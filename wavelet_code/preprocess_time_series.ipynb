{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_510118/184408677.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from shapely.geometry import Point\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import CityHub\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossref(df, gdf):\n",
    "    \"\"\"\n",
    "    Link rows of a dataframe to polygons in a geodataframe.\n",
    "    Dataframe must have columns 'LONGITUDE' and 'LATITUDE'.\n",
    "    \"\"\"\n",
    "    shapes = gdf.geometry\n",
    "    centroids = [x.centroid for x in shapes]\n",
    "    centroids = np.array([(x.x, x.y) for x in centroids])\n",
    "    nn = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(centroids)\n",
    "    _, indices = nn.kneighbors(df[['LONGITUDE', 'LATITUDE']])\n",
    "\n",
    "    id_poly = []\n",
    "    i = 0\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        point = Point(row['LONGITUDE'], row['LATITUDE'])\n",
    "        new_id = None\n",
    "        for idx in indices[i]:\n",
    "            if shapes[idx].contains(point):\n",
    "                new_id = idx\n",
    "                break\n",
    "        id_poly.append(new_id)\n",
    "        i += 1\n",
    "\n",
    "    df['id_poly'] = id_poly\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## São Paulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_range = [\"2019-12-01\", \"2020-01-15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_mapper = {\n",
    "    \"A NOITE\" : \"18:00:00\",\n",
    "    \"A TARDE\" : \"15:00:00\",\n",
    "    \"DE MADRUGADA\" : \"03:00:00\",\n",
    "    \"PELA MANHÃ\" : \"09:00:00\",\n",
    "    \"EM HORA INCERTA\" : None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_dates(day_range):\n",
    "    dates = pd.date_range(day_range[0], day_range[1], freq=\"D\")\n",
    "    # repeat with hours: 3h, 9h, 15h, 18h\n",
    "    new_dates = []\n",
    "    for d in dates:\n",
    "        new_dates.append(d + pd.Timedelta(hours=3))\n",
    "        new_dates.append(d + pd.Timedelta(hours=9))\n",
    "        new_dates.append(d + pd.Timedelta(hours=15))\n",
    "        new_dates.append(d + pd.Timedelta(hours=18))\n",
    "    return new_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_date(x):\n",
    "    hour = x.hour\n",
    "    if 6 <= hour < 12:\n",
    "        new_hour = 9\n",
    "    elif 12 <= hour < 18:\n",
    "        new_hour = 15\n",
    "    elif 18 <= hour < 24:\n",
    "        new_hour = 18\n",
    "    else:\n",
    "        new_hour = 3\n",
    "    return pd.to_datetime(f\"{x.date()} {new_hour}:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_division = \"SpCenterCensus2k\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000000\n",
    "df = pd.read_csv(\"data/time_series/waze-alerts.csv\")\n",
    "df = df[[\"geo\", \"ts\", \" type\"]]\n",
    "df = df.rename(columns = {\" type\" : \"type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = pd.to_datetime(df[\"ts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.date >= day_range[0]]\n",
    "df = df[df.date < day_range[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"LONGITUDE\"] = df[\"geo\"].apply(lambda x : x.split(\"(\")[1].split(\" \")[0])\n",
    "df[\"LATITUDE\"] = df[\"geo\"].apply(lambda x : x.split(\" \")[1].split(\")\")[0])\n",
    "df.LONGITUDE = df.LONGITUDE.astype(float)\n",
    "df.LATITUDE = df.LATITUDE.astype(float)\n",
    "df[\"type\"] = df[\"type\"].apply(lambda x : \"ROADCLOSED\" if x == \"ROAD_CLOSED\" else x)\n",
    "df = df[df.date >= day_range[0]]\n",
    "df = df[df.date < day_range[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovani/anaconda3/envs/wavelet_code/lib/python3.10/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but NearestNeighbors was fitted without feature names\n",
      "  warnings.warn(\n",
      "100%|██████████| 1224134/1224134 [02:13<00:00, 9177.41it/s]\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file(f\"data/shapefiles/{poly_division}.geojson\")\n",
    "df = crossref(df, gdf)\n",
    "df = df.dropna(subset = [\"id_poly\"])\n",
    "df[\"updated_date\"] = df[\"date\"].apply(simplify_date)\n",
    "df[\"id_poly\"] = df[\"id_poly\"].astype(int)\n",
    "n_poly = len(gdf)\n",
    "all_dates = get_all_dates(day_range)\n",
    "n_days = len(all_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in df.type.unique():\n",
    "    df_ = df[df.type == t].copy()\n",
    "    df_ = df_.groupby([\"id_poly\", \"updated_date\"]).size().reset_index()\n",
    "    ts = np.zeros((n_poly, n_days))\n",
    "    for i, d in enumerate(all_dates):\n",
    "        filtered = df_[df_.updated_date == d]\n",
    "        if len(filtered) == ts.shape[0]:\n",
    "            ts[:, i] = filtered[0]\n",
    "        else:\n",
    "            ts[filtered.id_poly, i] = filtered[0]\n",
    "    \n",
    "    area = gdf.to_crs(\"EPSG:6933\").area.values / 10**6\n",
    "    ts = ts / area[:, None]\n",
    "    np.save(f\"data/time_series/{t}_{poly_division}_Period1.npy\", ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime theft and robbery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_510118/2078175672.py:1: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/time_series/furto_celular_2018_2022.csv\", sep = \";\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of nan dates: 0.41\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/time_series/furto_celular_2018_2022.csv\", sep = \";\")\n",
    "df[\"hour\"] = df.PERIDOOCORRENCIA.apply(lambda x : hour_mapper[x])\n",
    "df[\"date\"] = pd.to_datetime(df.DATAOCORRENCIA, format='%d/%m/%Y', errors='coerce')\n",
    "df[\"date\"] = df[\"date\"] + pd.to_timedelta(df[\"hour\"], errors='coerce')\n",
    "print(f\"Fraction of nan dates: {df.date.isna().mean():.2f}\")\n",
    "df = df.dropna(subset = [\"date\"])\n",
    "df = df[[\"date\", \"LATITUDE\", \"LONGITUDE\"]]\n",
    "df = df[df.date >= day_range[0]]\n",
    "df = df[df.date < day_range[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovani/anaconda3/envs/wavelet_code/lib/python3.10/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but NearestNeighbors was fitted without feature names\n",
      "  warnings.warn(\n",
      "100%|██████████| 5391/5391 [00:00<00:00, 8972.81it/s]\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file(f\"data/shapefiles/{poly_division}.geojson\")\n",
    "df = crossref(df, gdf)\n",
    "df = df.dropna(subset = [\"id_poly\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"id_poly\"] = df[\"id_poly\"].astype(int)\n",
    "n_poly = len(gdf)\n",
    "all_dates = get_all_dates(day_range)\n",
    "n_days = len(all_dates)\n",
    "df = df.groupby([\"id_poly\", \"date\"]).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.zeros((n_poly, n_days))\n",
    "for i, d in enumerate(all_dates):\n",
    "    filtered = df[df.date == d]\n",
    "    if len(filtered) == ts.shape[0]:\n",
    "        ts[:, i] = filtered[0]\n",
    "    else:\n",
    "        ts[filtered.id_poly, i] = filtered[0]\n",
    "\n",
    "area = gdf.to_crs(\"EPSG:6933\").area.values / 10**6\n",
    "ts = ts / area[:, None]\n",
    "np.save(f\"data/time_series/FurtoCelular_{poly_division}_Period1.npy\", ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime robbery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_510118/665113477.py:1: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/time_series/roubo_celular_2018_2022.csv\", sep = \";\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of nan dates: 0.01\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/time_series/roubo_celular_2018_2022.csv\", sep = \";\")\n",
    "df[\"hour\"] = df.PERIDOOCORRENCIA.apply(lambda x : hour_mapper[x])\n",
    "df[\"date\"] = pd.to_datetime(df.DATAOCORRENCIA, format='%d/%m/%Y', errors='coerce')\n",
    "df[\"date\"] = df[\"date\"] + pd.to_timedelta(df[\"hour\"], errors='coerce')\n",
    "print(f\"Fraction of nan dates: {df.date.isna().mean():.2f}\")\n",
    "df = df.dropna(subset = [\"date\"])\n",
    "df = df[[\"date\", \"LATITUDE\", \"LONGITUDE\"]]\n",
    "df = df[df.date >= day_range[0]]\n",
    "df = df[df.date < day_range[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovani/anaconda3/envs/wavelet_code/lib/python3.10/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but NearestNeighbors was fitted without feature names\n",
      "  warnings.warn(\n",
      "100%|██████████| 17346/17346 [00:01<00:00, 9216.71it/s]\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file(f\"data/shapefiles/{poly_division}.geojson\")\n",
    "df = crossref(df, gdf)\n",
    "df = df.dropna(subset = [\"id_poly\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"id_poly\"] = df[\"id_poly\"].astype(int)\n",
    "n_poly = len(gdf)\n",
    "all_dates = get_all_dates(day_range)\n",
    "n_days = len(all_dates)\n",
    "df = df.groupby([\"id_poly\", \"date\"]).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.zeros((n_poly, n_days))\n",
    "for i, d in enumerate(all_dates):\n",
    "    filtered = df[df.date == d]\n",
    "    if len(filtered) == ts.shape[0]:\n",
    "        ts[:, i] = filtered[0]\n",
    "    else:\n",
    "        ts[filtered.id_poly, i] = filtered[0]\n",
    "\n",
    "area = gdf.to_crs(\"EPSG:6933\").area.values / 10**6\n",
    "ts = ts / area[:, None]\n",
    "np.save(f\"data/time_series/RouboCelular_{poly_division}_Period1.npy\", ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unify time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_naming = {\n",
    "    \"JAM\": \"Jam\",\n",
    "    \"ACCIDENT\": \"Accident\",\n",
    "    \"ROADCLOSED\": \"Road Closed\",\n",
    "    \"WEATHERHAZARD\": \"Weather Hazard\",\n",
    "    \"FurtoCelular\": \"Phone Theft\",\n",
    "    \"RouboCelular\": \"Phone Robbery\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = [np.load(f\"data/time_series/{key}_{poly_division}_Period1.npy\") for key in features_naming.keys()]\n",
    "ts_sum = [np.sum(t) for t in ts]\n",
    "ts = [t for i, t in enumerate(ts) if ts_sum[i] > 0]\n",
    "signals = [s for i, s in enumerate(features_naming.keys()) if ts_sum[i] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368000, 8)\n"
     ]
    }
   ],
   "source": [
    "date = get_all_dates(day_range)\n",
    "df = []\n",
    "for poly in range(ts[0].shape[0]):\n",
    "    for t in range(ts[0].shape[1]):\n",
    "        df.append({\n",
    "            \"date\" : date[t],\n",
    "            \"id_poly\" : poly,\n",
    "        })\n",
    "        for i, signal in enumerate(signals):\n",
    "            df[-1][\n",
    "                features_naming[signal]\n",
    "            ] = ts[i][poly, t]\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "print(df.shape)\n",
    "df.to_csv(f\"data/polygon_data/{poly_division}_Period1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for i in range(1, 7):\n",
    "    df_ = pd.read_csv(f\"data/time_series/yellow_taxi_2016_0{i}.csv\")\n",
    "    # remove rows with trip_distance bigger than 500km\n",
    "    df_ = df_[df_.trip_distance < 500]\n",
    "    df_ = df_.sample(10**6//6, random_state = 0)\n",
    "    df.append(df_)\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"data/shapefiles/NYBlocks.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_369222/2284987300.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"date\"] = pd.to_datetime(df[\"tpep_pickup_datetime\"])\n"
     ]
    }
   ],
   "source": [
    "df[\"LONGITUDE\"] = df[\"pickup_longitude\"]\n",
    "df[\"LATITUDE\"] = df[\"pickup_latitude\"]\n",
    "df[\"date\"] = pd.to_datetime(df[\"tpep_pickup_datetime\"])\n",
    "df = df.drop(columns = [\"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\", \"tpep_dropoff_datetime\", \"tpep_pickup_datetime\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovani/anaconda3/envs/wavelet_code/lib/python3.10/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but NearestNeighbors was fitted without feature names\n",
      "  warnings.warn(\n",
      "100%|██████████| 999996/999996 [01:36<00:00, 10312.96it/s]\n"
     ]
    }
   ],
   "source": [
    "df = crossref(df, gdf)\n",
    "df = df.dropna(subset = [\"id_poly\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_ns = 60*60*24*10**9\n",
    "df[\"date_int\"] = df.date.astype(int)\n",
    "df[\"date_int\"] = df.date_int / day_ns\n",
    "df[\"date_int\"] = df.date_int.astype(int)    \n",
    "df = df.groupby([\"id_poly\", \"date_int\"]).agg({\"passenger_count\" : \"sum\", \"trip_distance\" : \"mean\", \"date\" : [\"min\", \"count\"]}).reset_index()\n",
    "df.columns = [\"id_poly\", \"date_int\", \"passanger_count\", \"trip_distance\", \"date\", \"n_pickups\"]\n",
    "df[\"id_poly\"] = df[\"id_poly\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove hour from date\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.floor('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_range = [\"2016-01-01\", \"2016-07-01\"]\n",
    "day_ns = 60*60*24*10**9\n",
    "time_aux = pd.Series(ny_range).apply(pd.to_datetime)\n",
    "time_aux = (time_aux.astype(int) / day_ns).astype(int)\n",
    "min_date = time_aux.min()\n",
    "max_date = time_aux.max()\n",
    "n_days = int(max_date - min_date)\n",
    "n_poly = len(gdf)\n",
    "ts = np.zeros((n_poly, n_days, 3))\n",
    "k = 0\n",
    "for day in range(min_date, max_date):\n",
    "    filtered = df[df.date_int == day]\n",
    "    if len(filtered) == ts.shape[0]:\n",
    "        ts[:, k, :] = filtered[[\"passanger_count\", \"trip_distance\", \"n_pickups\"]]\n",
    "    else:\n",
    "    # fill missing values with 0\n",
    "        ts[:, k] = 0\n",
    "        ts[filtered.id_poly, k, :] = filtered[[\"passanger_count\", \"trip_distance\", \"n_pickups\"]]\n",
    "    k += 1\n",
    "\n",
    "# change to a projection with meters as unit\n",
    "area = gdf.to_crs(\"EPSG:6933\").area.values / 10**6\n",
    "ts = ts / area[:, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"PassangerCount\", \"TripDistance\", \"NPickups\"]\n",
    "for i in range(3):\n",
    "    np.save(f\"data/time_series/{features[i]}_NYBlocks_Day.npy\", ts[:, :, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for i in range(1, 7):\n",
    "    df_ = pd.read_csv(f\"data/time_series/yellow_taxi_2016_0{i}.csv\")\n",
    "    df_ = df_[df_.trip_distance < 500]\n",
    "    df_ = df_.sample(10**6//6, random_state = 0)\n",
    "    \n",
    "    df.append(df_)\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_369222/959207515.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"date\"] = pd.to_datetime(df[\"tpep_dropoff_datetime\"])\n"
     ]
    }
   ],
   "source": [
    "df[\"LONGITUDE\"] = df[\"dropoff_longitude\"]\n",
    "df[\"LATITUDE\"] = df[\"dropoff_latitude\"]\n",
    "df[\"date\"] = pd.to_datetime(df[\"tpep_dropoff_datetime\"])\n",
    "df = df[[\"LONGITUDE\", \"LATITUDE\", \"date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"data/shapefiles/NYBlocks.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovani/anaconda3/envs/wavelet_code/lib/python3.10/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but NearestNeighbors was fitted without feature names\n",
      "  warnings.warn(\n",
      "100%|██████████| 999996/999996 [01:35<00:00, 10432.41it/s]\n"
     ]
    }
   ],
   "source": [
    "df = crossref(df, gdf)\n",
    "df = df.dropna(subset = [\"id_poly\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_ns = 60*60*24*10**9\n",
    "df[\"date_int\"] = df.date.astype(int)\n",
    "df[\"date_int\"] = df.date_int / day_ns\n",
    "df[\"date_int\"] = df.date_int.astype(int)    \n",
    "df = df.groupby([\"id_poly\", \"date_int\"]).size().reset_index()\n",
    "df.columns = [\"id_poly\", \"date_int\", \"count\"]\n",
    "df[\"id_poly\"] = df[\"id_poly\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_range = [\"2016-01-01\", \"2016-07-01\"]\n",
    "day_ns = 60*60*24*10**9\n",
    "time_aux = pd.Series(ny_range).apply(pd.to_datetime)\n",
    "time_aux = (time_aux.astype(int) / day_ns).astype(int)\n",
    "min_date = time_aux.min()\n",
    "max_date = time_aux.max()\n",
    "n_days = int(max_date - min_date)\n",
    "n_poly = len(gdf)\n",
    "ts = np.zeros((n_poly, n_days))\n",
    "k = 0\n",
    "for day in range(min_date, max_date):\n",
    "    filtered = df[df.date_int == day]\n",
    "    if len(filtered) == ts.shape[0]:\n",
    "        ts[:, k] = filtered[\"count\"]\n",
    "    else:\n",
    "    # fill missing values with 0\n",
    "        ts[:, k] = 0\n",
    "        ts[filtered.id_poly, k] = filtered[\"count\"]\n",
    "    k += 1\n",
    "\n",
    "# change to a projection with meters as unit\n",
    "area = gdf.to_crs(\"EPSG:6933\").area.values / 10**6\n",
    "ts = ts / area[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"data/time_series/NDropoffs_NYBlocks_Day.npy\", ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unify time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NDropoffs', 'NPickups', 'PassangerCount', 'TripDistance']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signals = glob.glob(\"data/time_series/*NYBlocks*\")\n",
    "signals = [s.split(\"_\")[-3] for s in signals]\n",
    "signals = [s.split(\"/\")[-1] for s in signals]\n",
    "signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212576, 6)\n"
     ]
    }
   ],
   "source": [
    "poly_division = \"NYBlocks\"\n",
    "time_interval = \"Day\"\n",
    "ts = [\n",
    "    np.load(f\"data/time_series/{signal}_{poly_division}_{time_interval}.npy\") for signal in signals\n",
    "]\n",
    "# drop if all values are 0\n",
    "ts_sum = [np.sum(t) for t in ts]\n",
    "ts = [t for i, t in enumerate(ts) if ts_sum[i] > 0]\n",
    "signals = [s for i, s in enumerate(signals) if ts_sum[i] > 0]\n",
    "df = []\n",
    "date = pd.date_range(start = ny_range[0], end = ny_range[1], freq = \"d\")\n",
    "poly_id = np.arange(ts[0].shape[0])\n",
    "for poly in range(ts[0].shape[0]):\n",
    "    for t in range(ts[0].shape[1]):\n",
    "        df.append({\n",
    "            \"date\" : date[t],\n",
    "            \"id_poly\" : poly_id[poly],\n",
    "        })\n",
    "        for i, signal in enumerate(signals):\n",
    "            df[-1][signal] = ts[i][poly, t]\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "print(df.shape)\n",
    "df.to_csv(f\"data/polygon_data/{poly_division}_{time_interval}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLA Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"data/shapefiles/BLACities.geojson\")\n",
    "name = gdf.name.tolist()\n",
    "id_poly = gdf.id_poly.tolist()\n",
    "df = pd.read_csv(\"data/time_series/cities_time_series.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "father_classes_hierarchy = {\n",
    "    \"floresta\": [\n",
    "        \"formacao_florestal\",\n",
    "        \"formacao_savanica\",\n",
    "        \"mangue\",\n",
    "        \"restinga_arborizada\",\n",
    "    ],\n",
    "    \"formacao_natural_nao_florestal\": [\n",
    "        \"campo_alagado_e_area_pantanosa\",\n",
    "        \"formacao_campestre\",\n",
    "        \"apicum\",\n",
    "        \"afloramento_rochoso\",\n",
    "        \"outras_formacoes_nao_florestais\",\n",
    "    ],\n",
    "    \"agropecuaria\": [\n",
    "        \"pastagem\",\n",
    "        \"soja\",\n",
    "        \"cana\",\n",
    "        \"arroz\",\n",
    "        \"outras_lavouras_temporarias\",\n",
    "        \"cafe\",\n",
    "        \"citrus\",\n",
    "        \"outras_lavouras_perenes\",\n",
    "        \"floresta_plantada\",\n",
    "        \"moisaco_de_agricultura_e_pastagem\",\n",
    "    ],\n",
    "    \"area_nao_vegetada\": [\n",
    "        \"praia_e_duna\",\n",
    "        \"infraestrutura_urbana\",\n",
    "        \"mineracao\",\n",
    "        \"outras_areas_nao_vegetadas\",\n",
    "    ],\n",
    "    \"corpo_dagua\": [\"rio_lago_e_oceano\", \"aquicultura\"],\n",
    "    \"nao_observado\": [\n",
    "        \"nao_observado\",  # \"nao_classificado\"\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for father, children in father_classes_hierarchy.items():\n",
    "    df[father] = df[children].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\"formacao_florestal\", \"formacao_savanica\", \"formacao_natural_nao_florestal\", \"pastagem\", \"soja\", \"cana\", \"mineracao\", \"infraestrutura_urbana\", \"moisaco_de_agricultura_e_pastagem\", \"mangue\"]\n",
    "features_naming = {\n",
    "    \"formacao_florestal\" : \"Forest Formation\",\n",
    "    \"formacao_savanica\" : \"Cerrado\",\n",
    "    \"formacao_natural_nao_florestal\" : \"Natural Formation\",\n",
    "    \"pastagem\" : \"Pasture\",\n",
    "    \"soja\" : \"Soy\",\n",
    "    \"cana\" : \"Sugar Cane\",\n",
    "    \"mineracao\" : \"Mining\",\n",
    "    \"infraestrutura_urbana\" : \"Urban Infrastructure\",\n",
    "    \"moisaco_de_agricultura_e_pastagem\" : \"Mosaic Agriculture\",\n",
    "    \"mangue\" : \"Mangrove\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = []\n",
    "for year in df.year.unique():\n",
    "    df_ = df[df.year == year]\n",
    "    new_df = {\n",
    "        \"id_poly\" : id_poly,\n",
    "    }\n",
    "    for column in selected_columns:\n",
    "        new_df[features_naming[column]] = df_[column]\n",
    "    new_df = pd.DataFrame(new_df)\n",
    "    new_df[\"date\"] = pd.to_datetime(f\"{year}-01-01\")\n",
    "    df_result.append(new_df)\n",
    "df_result = pd.concat(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place date and id_poly as first columns\n",
    "cols = df_result.columns.tolist()\n",
    "cols.remove(\"date\")\n",
    "cols.remove(\"id_poly\")\n",
    "cols = [\"date\", \"id_poly\"] + cols\n",
    "df_result = df_result[cols]\n",
    "df_result = df_result.sort_values([\"id_poly\", \"date\"])\n",
    "df_result.to_csv(\"data/polygon_data/BLACities_Year.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wavelet_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
